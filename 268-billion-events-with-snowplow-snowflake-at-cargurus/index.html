<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.20">
<link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Bostata RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Bostata Atom Feed"><title data-rh="true">268 Billion Events With Snowplow and Snowflake at Cargurus | Bostata</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://your-docusaurus-test-site.com/268-billion-events-with-snowplow-snowflake-at-cargurus"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="268 Billion Events With Snowplow and Snowflake at Cargurus | Bostata"><meta data-rh="true" name="description" content="Two years ago we set up Open-Source Snowplow at CarGurus to fulfill a need for self-managed client-side instrumentation. Since that time it has become incredibly impactful for the entire company and has scaled significantly beyond what was originally envisioned. The following is an overview of why we set up the system, our experience with it, what we have learned, and where we see it continuing to go."><meta data-rh="true" property="og:description" content="Two years ago we set up Open-Source Snowplow at CarGurus to fulfill a need for self-managed client-side instrumentation. Since that time it has become incredibly impactful for the entire company and has scaled significantly beyond what was originally envisioned. The following is an overview of why we set up the system, our experience with it, what we have learned, and where we see it continuing to go."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-06-15T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="snowplow,snowflake,cargurus"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-test-site.com/268-billion-events-with-snowplow-snowflake-at-cargurus"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/268-billion-events-with-snowplow-snowflake-at-cargurus" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/268-billion-events-with-snowplow-snowflake-at-cargurus" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.9b0d8e9b.css">
<link rel="preload" href="/assets/js/runtime~main.2fc05b10.js" as="script">
<link rel="preload" href="/assets/js/main.5316f307.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title text--truncate">Bostata</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Blog</a><div class="toggle_S7eR colorModeToggle_vKtC"><button class="clean-btn toggleButton_rCf9 toggleButtonDisabled_Pu9x" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_dLyj"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_TMXw thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_V4zb margin-bottom--md">Recent posts</div><ul class="sidebarItemList_uHd5 clean-list"><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/staying-fresh-with-freshness-tables">Staying Fresh with Freshness Tables</a></li><li class="sidebarItem_spIe"><a aria-current="page" class="sidebarItemLink_eqrF sidebarItemLinkActive_XZSJ" href="/268-billion-events-with-snowplow-snowflake-at-cargurus">268 Billion Events With Snowplow and Snowflake at Cargurus</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/how-to-install-and-configure-snowsql">How To Install and Configure SnowSQL</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/gdpr-for-engineers-what-you-need-to-know">GDPR for Engineers - What You Need to Know</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/gdpr-for-engineers-what-is-personal-data">GDPR for Engineers - What is Personal Data?</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/client-side-instrumentation-for-under-one-dollar">Client-side instrumentation for under $1 per month. No servers necessary.</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/why-your-company-should-own-its-own-data">Why Your Company Should Own Its Own Data</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/data-pipeline-design-considerations">Data Pipeline Design Considerations</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">268 Billion Events With Snowplow and Snowflake at Cargurus</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2020-06-15T00:00:00.000Z" itemprop="datePublished">June 15, 2020</time> · <!-- -->17 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><span itemprop="name">Jake</span></div></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>Two years ago we set up Open-Source Snowplow at CarGurus to fulfill a need for self-managed client-side instrumentation. Since that time it has become incredibly impactful for the entire company and has scaled significantly beyond what was originally envisioned. The following is an overview of why we set up the system, our experience with it, what we have learned, and where we see it continuing to go.</p><p>This post is quite long, so before getting too far into the details....</p><h1>The Stats At Time of Writing</h1><p>Total events collected: <strong>&gt;268 billion</strong></p><p>Data collected: &gt; <strong>1.5pb (uncompressed)</strong></p><p>Event volume: <strong>~ 1 billion events/day</strong></p><p>Max Daily Throughput: <strong>~15k events/second (sustained during peak hours)</strong></p><p>Distinct events: <strong>hundreds and hundreds</strong></p><p>Infrastructure upgrade duration: <strong>less than two minutes with zero downtime</strong></p><p>Distinct sites with Snowplow tracking: <strong>&gt;180</strong></p><p>So let&#x27;s dive in.</p><h1>Why we Snowplow</h1><p>We chose Snowplow instead of building our own event tracking system, and plan to stick with it for the foreseeable future. Why?</p><p><strong>We wanted to independently manage and scale data collection systems.</strong></p><p>A conversation early in my tenure at CarGurus made a topic abundantly clear: many teams had a strong desire to separate concerns. At that time the company was growing quickly and demands were rapidly changing. Analysts and engineers were joining, onboarding fast, and asking completely new questions of our data. It was all-too-common to tell them their questions simply could not be answered due to the additional load tracking would place on production systems.
After being personally involved with a couple event-volume-related site outages, it was evident we needed to rethink data collection systems. We needed to be able to scale data collection infrastructure completely separately from application infrastructure, and we needed to significantly isolate the blast radius if something went wrong.</p><p>Snowplow was a strong ✅.</p><p><strong>We wanted to modernize event collection systems.</strong></p><p>Another requirement of choosing Snowplow was its ability to quickly and effectively introduce a lambda architecture into our analytics stack. As customer needs and demands evolved, we found that having both a real-time, low-latency (on the order of hundreds of milliseconds) component of the event pipeline as well as a batch-based, higher-latency (on the order of minutes) component gave us significant flexibility to proactively fulfill stakeholder asks before they surfaced.</p><p>Our pipelines are set up in AWS with Kinesis as transport and Snowflake as long-term data storage. As stakeholders need real-time access to enriched data, Kinesis is the go-to location. If stakeholders need access to historical event data or want to augment it with other sources in the data warehouse, Snowflake is the place to go.</p><p>Snowplow allowed us to introduce new ideas and methodologies and fulfill both point-in-time and future stakeholder needs. ✅</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="the-world-of-third-party-tracking-is-rapidly-changing-and-will-continue-to">The world of third-party tracking is rapidly changing and will continue to.<a class="hash-link" href="#the-world-of-third-party-tracking-is-rapidly-changing-and-will-continue-to" title="Direct link to heading">​</a></h3><p>As anyone involved in the world of client-side analytics is probably well-aware of, third-party tracking is increasingly going away. Initiatives like this and this and this are fantastic for online privacy (and commendable), but have major implications for tracking and analytics. With an eye towards the future we knew we needed to decrease reliance on Google Analytics, Adobe, Heap, and all other similar third-party tracking systems if we wanted full insight into web traffic. We wanted 100% of site behavior instead of sampled GA or ad-blocked Adobe. And we wanted to own the resulting data.</p><p>Snowplow enabled us to track first-party web activity and regain full visibility into usage behavior on our site. ✅</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="snowplow-sets-a-high-bar-for-fault-tolerance-redundancy-and-durability">Snowplow sets a high bar for fault-tolerance, redundancy, and durability.<a class="hash-link" href="#snowplow-sets-a-high-bar-for-fault-tolerance-redundancy-and-durability" title="Direct link to heading">​</a></h3><p>When set up properly, the Snowplow infrastructure is extremely fault-tolerant. We set up ours in AWS and have not regretted it whatsoever.
Javascript tracking code buffers unsent events locally in the case of collection infrastructure being down. AWS application load balancers are multi-AZ and AWS maintains a good SLA for them. All access logs are retained for a period of time in case the load balancer is up but the rest of the system is down. Kinesis replicates data across three AZ&#x27;s by default, and retention can be configured up to 168 hours in the case of mid-pipeline enrichment outages. S3 is highly durable and highly available by default. And the list goes on....</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="we-wanted-to-own-all-data-that-was-generated">We wanted to own all data that was generated.<a class="hash-link" href="#we-wanted-to-own-all-data-that-was-generated" title="Direct link to heading">​</a></h3><p>As mentioned above, if we were going to invest time and money building scalable event-collection infrastructure, we simply had to own the outcome. It is a significant investment to get large-scale infrastructure and instrumentation off the ground, and it&#x27;s hard to do tracking in a way that doesn&#x27;t impose a burden on analysts down the road (think Google Analytics events).
We didn&#x27;t want to deal with API rate limiting when attempting to recover our data. We didn&#x27;t want to be tied to BigQuery, and we didn&#x27;t want our customers&#x27; data flowing through other companies&#x27; systems.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="we-needed-to-keep-data-quality-high">We needed to keep data quality high.<a class="hash-link" href="#we-needed-to-keep-data-quality-high" title="Direct link to heading">​</a></h3><p>When building out data collection and processing systems, it&#x27;s one thing to set up infrastructure. It&#x27;s a completely different story to keep quality high as priorities, teams, and customer demands shift. It&#x27;s even harder to impose more work in an attempt to keep data &quot;clean&quot;.</p><p>The way snowplow handles event validation and stream-redirection was a perfect fit in our case. After setting the system up we quickly found that leveraging Self-Describing Events and the associated jsonschemas empowered us to enforce data quality in a very low-friction way. Whenever events start flowing (with a bad push, etc) that don&#x27;t adhere to the implementing party&#x27;s jsonschema, they are redirected out of the &quot;good&quot; path for immediate review and recovery. Self-describing events (and jsonschemas) also gave us the ability to do some pretty neat automation, which will be covered later.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="the-world-of-compliance-is-changing-rapidly-and-we-needed-the-ability-to-audit-every-piece-of-information">The world of compliance is changing rapidly and we needed the ability to audit every piece of information.<a class="hash-link" href="#the-world-of-compliance-is-changing-rapidly-and-we-needed-the-ability-to-audit-every-piece-of-information" title="Direct link to heading">​</a></h3><p>Since we first set up Snowplow the world has been forced to navigate two big data-privacy hurdles: GDPR and CCPA. Since we own and operate all collection infrastructure we did not need to get a third-party vendor DPA. Snowplow gives a significant amount of flexibility for enriching and redirecting PII, as well as configurable pseudonymization. It&#x27;s good, it &quot;just works&quot;, and it has saved us a considerable amount of time.</p><p>We&#x27;ve also spent a significant amount of time persisting full system lineage when splitting events into Snowflake which makes it easy to fully adhere to privacy legislation and associated requirements.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="we-wanted-to-build-guide-and-get-out-of-the-way">We wanted to build, guide, and get out of the way.<a class="hash-link" href="#we-wanted-to-build-guide-and-get-out-of-the-way" title="Direct link to heading">​</a></h3><p>My favorite part about programming and tech is building (machine) processes, cultivating good (human) habits, and getting out of the way. An early challenge was maintaining clear, consistent definitions of data between frontend engineers (the implementer of tracking) and analysts (the stakeholders of said tracking). Event data was previously tracked, flowed through a number of different systems, and was often renamed (sometimes several times) when it finally landed in Snowflake.. Snowplow&#x27;s self-describing events have allowed us to shift many conversations away from data pipeline engineers and back to where they should be taking place. I was able to back away since stakeholders and implementers were able to approach important conversations from a point of shared, consistent understanding.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="last-but-not-least-we-needed-to-hit-the-ground-running">Last but not least, we needed to hit the ground running.<a class="hash-link" href="#last-but-not-least-we-needed-to-hit-the-ground-running" title="Direct link to heading">​</a></h3><p>While we may have had time to build out our own system from scratch, why build when you can lean on the backs of giants? The community of people contributing to Snowplow has grown significantly since the first time I implemented it, and people all over the world have run into almost every challenge imaginable. As fun as it would have been to deconstruct the system and build and implement our own, it simply wasn&#x27;t worth it. Our stakeholders had questions that they wanted answered &quot;yesterday&quot; and their needs were our priority #1.</p><p>Snowplow enabled us to hit the ground running and answer real business questions &quot;now&quot;. ✅</p><h1>Our Journey</h1><h2 class="anchor anchorWithStickyNavbar_mojV" id="phase-1-keep-it-simple-get-it-running-prove-the-systems-worth">Phase 1: Keep It Simple. Get It Running. Prove the System&#x27;s Worth.<a class="hash-link" href="#phase-1-keep-it-simple-get-it-running-prove-the-systems-worth" title="Direct link to heading">​</a></h2><p>When Snowplow was first rolled out there was a single mission in mind: make sure it was a good organizational fit. We had systems in place with some functional overlap already, so we had to make sure we weren&#x27;t introducing a new system simply........ for the sake of introducing a new system. Or staking claim in others&#x27; territory. The system had to work. It had to answer questions that had been previously-unanswerable. It had to be robust. And it had to solve real-life challenges.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="we-very-consciously-chose-to">We very consciously chose to:<a class="hash-link" href="#we-very-consciously-chose-to" title="Direct link to heading">​</a></h3><p><strong>Automate all infrastructure.</strong> We wanted to scale, upgrade, and roll out entirely new sets of infrastructure fast. Everything was Terraformed and infrastructure was 100% immutable.</p><p><strong>Keep it simple.</strong> We could have gone straight to k8s or autoscaling clusters or ecs or eks or any other new (admittedly attractive) thing. But we didn&#x27;t. We wanted to see how the system itself would perform and scale.</p><p><strong>Focus on the stakeholder.</strong> The only way this initiative was going to work was if others felt ownership of it, it decreased their pain, it empowered them to do their jobs better, or a combination of all. Instead of focusing on a hip/cool/hot/new system we focused on answering the questions at hand.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="phase-2-ramp-adoption-answer-more-questions">Phase 2: Ramp Adoption. Answer More Questions.<a class="hash-link" href="#phase-2-ramp-adoption-answer-more-questions" title="Direct link to heading">​</a></h2><p>Once the system was set up and a minimal set of events were implemented across our site, we started really putting the system to work. We went around the company figuring out what questions people had been historically struggling to answer, and then helped implement the necessary tracking to answer these questions. We also pushed the system in other ways, such as seeing how effective it was for third-party tracking on other websites, redirect tracking, no-js tracking, and more.</p><p>We originally rolled out most of the tracking via structured events. While great for adoption, it was evident things would quickly get out of hand before realizing the full value of the system if we continued down this path. Json-encoded strings with arbitrary values were being passed as se_property. Event definitions were unclear and quickly inconsistent. Snowflake query duration (and therefore cost) was going through the roof as people tried to pull data out of a single poorly-clustered &quot;struct_events&quot; table. And more.</p><p>While we were able to answer questions, it was clear this methodology of doing so would be unsustainable and/or expensive long term.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="phase-3-go-all-in-on-mandating-data-quality">Phase 3: Go All-In on Mandating Data Quality.<a class="hash-link" href="#phase-3-go-all-in-on-mandating-data-quality" title="Direct link to heading">​</a></h2><p>After quickly learning the pain points associated with struct-event tracking in a company our size we had a decision to make: <strong>go all-in on self-describing events or bust.</strong></p><p>Admittedly, mandating that events only get successfully delivered when accompanied by a jsonschema is a bit of overhead that is passed to the implementer. In this case, quality comes at a small time cost. But said cost is more than worth it.</p><p><strong>Why it&#x27;s worth using schemas:</strong></p><ul><li>Data can be explicitly defined and versioned. Schema evolution is possible without blowing up the world of analytics.</li><li>Self-describing events can be independently monitored and alerted on.</li><li>Incoming events are validated and redirected in-transit.</li><li>Jsonschemas establish consistency and empower 1:1 communication.</li><li>Significant downstream automation can be built on top of schemas. Auto-migrating tables, splitting/deduplicating events, and intelligently clustering tables in snowflake are only possible with self-describing events.</li><li>&quot;Bad&quot; event volume can be alerted on and directed to the respective team.</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="phase-4-solidify-infrastructure-add-necessary-complexity-automate-data-engineering-toil-away">Phase 4: Solidify Infrastructure. Add Necessary Complexity. Automate Data Engineering Toil Away.<a class="hash-link" href="#phase-4-solidify-infrastructure-add-necessary-complexity-automate-data-engineering-toil-away" title="Direct link to heading">​</a></h2><p>Once we knew the system would work and that it was a good organizational fit, the next step was to make the supporting infrastructure rock-solid.</p><p>Originally setting up the system in the simplest manner possible meant that we willingly accepted tradeoffs and some risk. We had to make sure we had enough machines behind the load balancer to service traffic at any point in time. We had to closely (and sometimes manually!) monitor the enrichment and s3 loader machines. And we had to manually scale supporting infrastructure when necessary. From a cost and utilization perspective, we ran the system slightly over-provisioned during peak volume and significantly over-provisioned during the slowest points of the day. The simplicity came at a cost tradeoff, but again - there&#x27;s very little point in optimizing a system that you&#x27;re not going to continue using.</p><p>As we became more confident in the long-term direction of this project it was time to buckle down and set up all infrastructure in a way that we could step away from. This ultimately meant containerizing all systems, introducing auto-scaling groups with reasonable scaling policies, auto-scaling dynamodb, figuring out how to reasonably auto-scale kinesis, and a number of other not-too-complicated-but-incredibly-important devops things. We decided to run EC2 ASG&#x27;s of flatcar container linux vs running the containers on ECS, EKS, or a k8s cluster, though one of those will probably be in our future.</p><p>Another critical aspect of this automation was the implementation of a load/deduplicate/split/auto-cluster system. We have pipelines geolocated all over the world and load all data into Snowflake. By leveraging self-describing event json-schemas mandated in Phase 2, we were able to auto-migrate Snowflake tables, auto-split events into said tables, efficiently deduplicate events, strategically cluster, and much much more.</p><p>The automation here has saved us considerable amounts of time and money, and has allowed us to go incredibly far by automating ourselves away.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="phase-5-decrease-implementation-overhead-dont-sacrifice-data-quality">Phase 5: Decrease Implementation Overhead. Don&#x27;t Sacrifice Data Quality.<a class="hash-link" href="#phase-5-decrease-implementation-overhead-dont-sacrifice-data-quality" title="Direct link to heading">​</a></h2><p>This is the phase we are in currently and it&#x27;s a very important one. As a data engineer, if you get data quality wrong (even unintentionally!), it can easily lead a company in a bad direction and will create massive problems that take years to resolve. We did not want to make these mistakes, so we quickly pivoted towards strictly prioritizing data quality. But we believe that&#x27;s not the end of the story. If we can mandate data quality while making schemas as easy to implement, deploy, evolve, and monitor as not having them at all, we&#x27;ll consider it a massive success. We also strive towards establishing clear, consistent, sharable definitions for all and make all definitions easily searchable.</p><p>At this point we are well on our way to achieving these goals. But we aren&#x27;t quite there yet.</p><h1>What we have done a bit differently</h1><p>The snowplow stream collector, the stream enricher, and the s3 loader are basically out-of-the-box and have been configured to suit our needs and volume. But we&#x27;ve gone a slightly differently direction with other core aspects of the system.</p><p>We decided not to use the snowplow snowflake loader largely due to avoiding additional dependencies, needing more flexibility, and desiring to process and store data consistently to other internal systems. We have a significant amount of professional experience with Snowflake administration/automation, and saw opportunity to make our lives a bit easier long term if we rolled this portion of the pipeline ourselves.</p><p>We decided not to use the iglu schema repository (but do use jsonschemas for self-described events!) due to identifying numerous opportunities at this level. This functionality may be covered in another future blog post.</p><p>We love Graylog, fluent-bit, and a handful of other tools. So we&#x27;ve incorporated them in useful ways.</p><h1>What we have learned along the way</h1><h3 class="anchor anchorWithStickyNavbar_mojV" id="stakeholder-empowerment-is-1">Stakeholder empowerment is #1.<a class="hash-link" href="#stakeholder-empowerment-is-1" title="Direct link to heading">​</a></h3><p>I cannot stress this enough: the only way to make initiatives like this work is by taking a customer-focused, stakeholder-oriented approach. As a data engineer my customers are typically analysts or various business intelligence initiatives. But as data maturity grows in the organization the word &quot;stakeholder&quot; evolves to also include other internal systems, and then SEO optimization, potentially strategic partnerships with other orgs, external customers, and much more.</p><p>By running Snowplow and leaning into significant Snowflake automation my role has become less gatekeeper and more facilitator, working alongside stakeholders to achieve the respective end goal.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="infrastructure-and-system-automation-is-2">Infrastructure and system automation is #2.<a class="hash-link" href="#infrastructure-and-system-automation-is-2" title="Direct link to heading">​</a></h3><p>Setting up and thoroughly understanding the Snowplow stack on AWS is non-trivial. There&#x27;s a significant number of moving pieces and a deep understanding of Kinesis internals is required to manage it well. We automated everything from the very start so spinning up and properly configuring 70+ AWS resources per pipeline becomes (almost) trivial.</p><p>Another benefit of full infrastructure automation is the ability to shut systems down cleanly when we don&#x27;t need them anymore, and make code central to infrastructure rollouts.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="explicitly-mandating-data-quality-has-numerous-benefits-it-may-come-at-a-cost-but-it-doesnt-have-to">Explicitly mandating data quality has numerous benefits. It may come at a cost, but it doesn&#x27;t have to.<a class="hash-link" href="#explicitly-mandating-data-quality-has-numerous-benefits-it-may-come-at-a-cost-but-it-doesnt-have-to" title="Direct link to heading">​</a></h3><p>Leaning into 100% self-describing Snowplow events admittedly comes with operational overhead. &quot;Bad&quot; must scale as cleanly as &quot;good&quot; in the case that a high number of events are redirected. Otherwise, the &quot;pipes&quot; will become constricted and the entire system will back up. Event schemas must be properly-validated json before being deployed into production pipelines. Front-end engineers must be personally invested in helping to mandate data quality, and using jsonschemas to validate each piece of instrumentation is new cognitive load.</p><p>We&#x27;ve leaned into automation and/or internal tooling here as well to help reduce this overhead, but there&#x27;s much further to go.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="the-snowplowsnowflake-combination-scales-extremely-well-it-has-empowered-us-to-answer-many-previously-unanswerable-questions-and-has-opened-up-numerous-doors-of-opportunity">The Snowplow+Snowflake combination scales extremely well. It has empowered us to answer many previously-unanswerable questions and has opened up numerous doors of opportunity.<a class="hash-link" href="#the-snowplowsnowflake-combination-scales-extremely-well-it-has-empowered-us-to-answer-many-previously-unanswerable-questions-and-has-opened-up-numerous-doors-of-opportunity" title="Direct link to heading">​</a></h3><p>I have personally run open-source Snowplow analytics a large number of times with AWS Redshift as a data warehouse. While functional, it quickly becomes a burden to maintain and scale. The Snowplow+Snowflake combination is extremely effectively and extremely powerful. And scales well, even at CarGurus&#x27; volume.</p><h1>Where we see it continuing to go in the future</h1><h3 class="anchor anchorWithStickyNavbar_mojV" id="leverage-the-stream-luke">Leverage the stream, Luke<a class="hash-link" href="#leverage-the-stream-luke" title="Direct link to heading">​</a></h3><p>There&#x27;s so much more opportunity to leverage data in-transit that we&#x27;ve barely cracked the surface of. Streaming databases such as Materialize and KSQL show massive promise for continuing to decrease time-to-insight and are some of the most exciting data projects since PipelineDB. I&#x27;m thrilled at the ability to bolt functionality onto an existing system (vs. re-architecting it from scratch as demands change) and am very interested to see what the low-latency future holds.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="continued-focus-on-auditability-provenance-and-data-governance">Continued focus on auditability, provenance, and data governance.<a class="hash-link" href="#continued-focus-on-auditability-provenance-and-data-governance" title="Direct link to heading">​</a></h3><p>Have I mentioned self-describing events with jsonschemas are amazing? Another significant benefit of them is the ability to cleanly, quickly, and effectively track provenance from upstream systems, all the way through the pipeline, to a data warehouse. Provenance is quite easy.</p><p>When it comes to data governance and auditing, we took numerous intentional steps in our Snowflake loader to make finding and purging data upstream doable. Snowflake&#x27;s  METADATA$FILENAME  and  METADATA$FILE_ROW_NUMBER  functionality means that if anyone requests removal of data (per GDPR) or requests data not be sold (per CCPA), it can be purged or excluded from both Snowflake as well as upstream flat files sitting in S3/Glacier/etc.</p><p>Continue to empower stakeholders, developers, analysts</p><p>Last but certainly not least, identifying and eliminating points of misunderstanding, cognitive load, or implementation/development challenges remains top priority. &quot;Stakeholders&quot; may be fellow engineers, they may be analysts whose job is to use the data we&#x27;re collecting and warehousing, or they may be product owners whose job and decision-making process relies on our data.</p><p>We&#x27;ll continue to push forward to make schema creation, discovery, evolution, and management more intuitive and fun.</p><p>We&#x27;ll continue to make real-time analytics a reality.</p><p>We&#x27;ll continue to make event-level observability and anomaly detection a critical part of instrumentation.</p><p>We&#x27;ll continue to push forward with automating ourselves out of the way.</p><p>And we&#x27;ll keep trying our best to make others&#x27; lives easier.</p><h1>In Conclusion</h1><p>If there&#x27;s any confusion by this point, the Snowplow and Snowflake combination has worked incredibly well for CarGurus. The company has leveraged these systems to blow open doors of opportunity and the system has proven itself time and time again over the past couple years.</p><p>Looking backwards, I&#x27;m quite happy with the rollout and have certainly learned a lot.</p><p>Looking forward I see only pure potential.</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/snowplow">snowplow</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/snowflake">snowflake</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/cargurus">cargurus</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/staying-fresh-with-freshness-tables"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Staying Fresh with Freshness Tables</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/how-to-install-and-configure-snowsql"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">How To Install and Configure SnowSQL</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.2fc05b10.js"></script>
<script src="/assets/js/main.5316f307.js"></script>
</body>
</html>